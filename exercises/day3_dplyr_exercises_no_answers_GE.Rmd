---
title: "dplyr Exercises Day 3"
author: "Richard Paquin Morel, adapted from exercises by Christina Maimone"
date: "`r Sys.Date()`"
output: html_document
params:
    answers: FALSE
---


```{r, echo=FALSE, eval=TRUE}
answers<-params$answers
```

```{r global_options, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(echo=answers, eval=answers,
                      warning = FALSE, message = FALSE,
                      cache = FALSE, tidy = FALSE)
```

## Load the data

Read both California energy datasets. Make sure you use `lubridate` to recode the `datetime` variable. Use `dplyr` to do this.


```{r}
#import
library(dplyr)
library(lubridate) #best way to deal with datetimes
generation <- read.csv(here::here("data/generation.csv"), 
                       stringsAsFactors = F)
imports <- read.csv(here::here("data/imports.csv"), 
                    stringsAsFactors = F)

```


```{asis}

```

```{r}
#datetimes
library(lubridate) #best way to deal with datetimes

generation <- mutate(generation, datetime = as_datetime(datetime))
imports <- mutate(imports, datetime = as_datetime(datetime))
```

```{r}
#exploring

str(generation)

head(generation)
```


## Merge and reshape the data

Using dplyr and pipes, merge the two datasets and then melt the resulting dataframe to make it tidy.


Principles of ???tidy data??? (R for Data Science - Wickham & Grolemund)
-Each variable must have its own column.
-Each observation must have its own row.
-Each value must have its own cell.
Often, we want to make wide data long (or tidy) for analysis

melt ???> make data long
dcast ???> make data wide
recast???> melt then cast data

```{asis}
### Answer
```

```{r}
library(dplyr)
library(reshape2)

long_gen <- melt(generation, id.vars='datetime', #the unit of observation. 
                variable.name= 'source', 
                value.name="usage"); 
 
long_gen

```

```{r}
long_gen[order(long_gen$datetime)[1:20], ] #ordering and viwing the first 20 rows and all columns
```


merge/join
```{r}

```


## Creating new variables

Create a series of new variables: 

1. `day`, which is the year-month-day, without the hour. The `lubridate` function `as_date` will do this.
2. `log_output`, which is the natural log of the output.
3. **Challenge**: `per_output`, which is the percent of daily output represented by each observation. You will need to use `group_by` and to create a new variable with the total output for the day. (Make sure to use `ungroup()` after this!)

Try to this all in one pipe!

```{asis}
### Answer
```

```{r}

```

## Summarizing and analyzing data

1. Which source has the greatest mean output by hour? (Hint: Use the dplyr verb `arrange(desc(variable))` to order the data frame so that the largest value of `variable` is first. Don't use `desc` and it arranges in ascending order.) Which has the least?
2. Which source has the greatest mean output by day? Which has the least?
3. Which sources has the greatest variance in usage over the course of a dataset? Which has the least?

```{asis}
### Answer
```

```{r}

```

```{r}

```

```{r}

```

## Analyzing renewable versus non-renewable energy sources

The dataset `regroup.csv` has information about which sources are considered renewable by the state of California. Use this dataset, along with your `dpylr` skills, to explore the use of renewable and non-renewable sources. Annotate what your descisions for the analysis.

Hint: Use your merge skills to merge the CA energy data with the `regroup` data. Which variable should you join by? 